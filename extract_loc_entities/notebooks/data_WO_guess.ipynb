{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip \n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "PATH = \"C:/Users/alpye/OneDrive/Desktop/DATA/coalition_3.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityList = []\n",
    "\n",
    "with open(\"data/cities.txt\", \"r\", encoding = \"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = unidecode(line)\n",
    "        line = line.strip().lower()\n",
    "        cityList.append(line)\n",
    "\n",
    "df = pd.read_excel('data/city_street.xlsx')\n",
    "\n",
    "ilce_dict = {}\n",
    "semt_dict = {}\n",
    "mah_dict = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    main_key = unidecode(row['il'].strip().lower())\n",
    "    sub_key = unidecode(row['ilçe'].strip().lower())\n",
    "    sub_sub_key = unidecode(row['semt_bucak_belde'].strip().lower())\n",
    "    value = (unidecode(row[\"Mahalle\"].strip().lower()))[:-4] # Exlude MAH\n",
    "\n",
    "    ilce_dict.setdefault(main_key, {}).setdefault(sub_key, 0)\n",
    "    semt_dict.setdefault(main_key, {}).setdefault(sub_sub_key, 0)\n",
    "    mah_dict.setdefault(main_key, {}).setdefault(value, 0)\n",
    "\n",
    "# DISCLAIMER: The values of these dictionaries were useless.\n",
    "# I realized that while I was making progress...\n",
    "\n",
    "# Make 3 seperate lists to check in the future\n",
    "\n",
    "ilce_list = []\n",
    "semt_list = []\n",
    "mah_list = []\n",
    "\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ilce = unidecode(row['ilçe'].strip().lower())\n",
    "    semt = unidecode(row['semt_bucak_belde'].strip().lower())\n",
    "    mah = (unidecode(row[\"Mahalle\"].strip().lower()))[:-4] # Exlude the MAH\n",
    "\n",
    "    if ilce not in ilce_list:\n",
    "        ilce_list.append(ilce)\n",
    "    if semt not in semt_list:\n",
    "        semt_list.append(semt)\n",
    "    if mah not in mah_list:\n",
    "        mah_list.append(mah)\n",
    "\n",
    "def find_main_key(nested_dict, middle_key):\n",
    "    for main_key, inner_dict in nested_dict.items():\n",
    "        if middle_key in inner_dict:\n",
    "            return main_key\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the JSON file as variable \"data\"\n",
    "\n",
    "with open(\"data/main_cities.json\", \"r\") as file:\n",
    "    city_data = json.load(file)\n",
    "\n",
    "# checks for [\"user\"][\"location\"], appends the user's id's in a list. Also adds to the city_data dictionary\n",
    "\n",
    "user_list = []\n",
    "\n",
    "memberCNT = 0\n",
    "cnt = 0\n",
    "with gzip.open(PATH, \"rt\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        for tweet in data:\n",
    "            if tweet[\"user\"][\"location\"] != '':\n",
    "                loc = unidecode(tweet[\"user\"][\"location\"].strip())\n",
    "                loc = loc.lower()\n",
    "                if \"/\" in loc:\n",
    "                    loc = loc.split(\"/\")\n",
    "                elif \",\" in loc:\n",
    "                    loc = loc.split(\",\")\n",
    "                else:\n",
    "                    loc = loc.split(\" \")\n",
    "                loc = [element.replace(\" \", \"\") for element in loc]\n",
    "\n",
    "                common_elements = set(loc).intersection(cityList)\n",
    "                if common_elements:\n",
    "                    city = list(common_elements)[0]\n",
    "                    city_data[city] += 1\n",
    "                    memberCNT += 1\n",
    "                    user_list.append(tweet[\"user\"][\"id\"])\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    common_elements = set(loc).intersection(ilce_list)\n",
    "                    if len(list(common_elements)) == 1:\n",
    "                        ilce = list(common_elements)[0]\n",
    "                        city = find_main_key(ilce_dict, ilce)\n",
    "                        city_data[city] += 1\n",
    "                        memberCNT += 1\n",
    "                        user_list.append(tweet[\"user\"][\"id\"])\n",
    "                        break\n",
    "                        \n",
    "                    else:\n",
    "                        common_elements = set(loc).intersection(semt_list)\n",
    "\n",
    "                        if len(list(common_elements)) == 1:\n",
    "                            \n",
    "                            semt = list(common_elements)[0]\n",
    "                            city = find_main_key(semt_dict, semt)\n",
    "                            \n",
    "                            city_data[city] += 1\n",
    "                            memberCNT += 1\n",
    "                            user_list.append(tweet[\"user\"][\"id\"])\n",
    "                            break\n",
    "\n",
    "                        else:\n",
    "                            common_elements = set(loc).intersection(mah_list)\n",
    "\n",
    "                            if len(list(common_elements)) == 1:\n",
    "                                \n",
    "                                mah = list(common_elements)[0]\n",
    "                                city = find_main_key(mah_dict, mah)\n",
    "                                \n",
    "                                city_data[city] += 1\n",
    "                                memberCNT += 1\n",
    "                                user_list.append(tweet[\"user\"][\"id\"])\n",
    "                                break\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"Successful Count\": memberCNT})         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime: 1 hour 8 minutes (on a script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Total users: 515 098\n",
    "Users with legit location in their bio: 117 678\n",
    "22.84%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/main_cities_finished_WO_guess.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(city_data, file, indent=4)\n",
    "\n",
    "with open('data/user_list_WO_guess.txt', 'w') as file:\n",
    "    for item in user_list:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_WO_guess.txt', 'r') as file:\n",
    "    user_list = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/main_cities_finished_WO_guess.json\", \"r\") as file:\n",
    "    city_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks for [\"place\"][\"full_name\"], appends the user's id's in a list. Also adds to the city_data dictionary\n",
    "\n",
    "user_place_id = []\n",
    "\n",
    "user_avoid = 0\n",
    "memberCNT = 0\n",
    "cnt = 0\n",
    "with gzip.open(PATH, \"rt\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        user_dict = {key: 0 for key in cityList}\n",
    "        went_in = False\n",
    "        for tweet in data:\n",
    "            if tweet[\"user\"][\"id\"] == user_list[user_avoid]:\n",
    "                if user_avoid < 117677:\n",
    "                    user_avoid += 1\n",
    "                break\n",
    "            else:\n",
    "                if tweet[\"place\"] is not None:\n",
    "                    loc = unidecode(tweet[\"place\"][\"full_name\"].strip())\n",
    "                    loc = loc.lower()\n",
    "                    if \"/\" in loc:\n",
    "                        loc = loc.split(\"/\")\n",
    "                    elif \",\" in loc:\n",
    "                        loc = loc.split(\",\")\n",
    "                    else:\n",
    "                        loc = loc.split(\" \")\n",
    "                    loc = [element.replace(\" \", \"\") for element in loc]\n",
    "\n",
    "                    common_elements = set(loc).intersection(cityList)\n",
    "                    if common_elements:\n",
    "                        city = list(common_elements)[0]\n",
    "                        user_dict[city] += 1\n",
    "                        went_in = True\n",
    "                        to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                        \n",
    "                    else:\n",
    "                        common_elements = set(loc).intersection(ilce_list)\n",
    "                        if len(list(common_elements)) == 1:\n",
    "                            \n",
    "                            ilce = list(common_elements)[0]\n",
    "                            city = find_main_key(ilce_dict, ilce)\n",
    "                            \n",
    "                            user_dict[city] += 1\n",
    "                            went_in = True\n",
    "                            to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                        \n",
    "                        else:\n",
    "                            common_elements = set(loc).intersection(semt_list)\n",
    "                            \n",
    "                            if len(list(common_elements)) == 1:\n",
    "                    \n",
    "                                semt = list(common_elements)[0]\n",
    "                                city = find_main_key(semt_dict, semt)\n",
    "                            \n",
    "                                user_dict[city] += 1\n",
    "                                went_in = True\n",
    "                                to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                                    \n",
    "\n",
    "                            else:\n",
    "                                common_elements = set(loc).intersection(mah_list)\n",
    "                                \n",
    "                                if len(list(common_elements)) == 1:\n",
    "                                    \n",
    "                                    mah = list(common_elements)[0]\n",
    "                                    city = find_main_key(mah_dict, mah)\n",
    "                                    \n",
    "                                    user_dict[city] += 1\n",
    "                                    went_in = True\n",
    "                                    to_be_appended = tweet[\"user\"][\"id\"]\n",
    "\n",
    "\n",
    "        if went_in:           \n",
    "            city = max(user_dict, key = user_dict.get)\n",
    "            city_data[city] += 1\n",
    "            memberCNT += 1\n",
    "            user_place_id.append(to_be_appended)\n",
    "            went_in = False                            \n",
    "                                \n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"Successful Count\": memberCNT, \"User List idx\": user_avoid})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Runtime: 23:52 (script)\n",
    "Users with legit geo info in their tweets (excluding the ones with geo info in their bio): 29 219\n",
    "5.67%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/main_cities_finished_2_WO_guess.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(city_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/main_cities_finished_2_WO_guess.json\", \"r\") as file:\n",
    "    city_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_place_WO_guess.txt', 'w') as file:\n",
    "    for item in user_place_id:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_place_WO_guess.txt', 'r') as file:\n",
    "    user_place_id = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ran on a script since it takes a long time, checked for [\"geo\"]\n",
    "\n",
    "user_geo_id = []\n",
    "\n",
    "\n",
    "df = gpd.read_file(\"data/turkey.geojson\")\n",
    "\n",
    "geoCnt = 0\n",
    "place_idx = 0\n",
    "userloc_idx = 0\n",
    "cnt = 0\n",
    "with gzip.open(PATH, \"rt\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        user_dict = {key: 0 for key in cityList}\n",
    "        went_in = False\n",
    "        for tweet in data:\n",
    "            if user_list[userloc_idx] == tweet[\"user\"][\"id\"]:\n",
    "                if userloc_idx < 117677:\n",
    "                    userloc_idx += 1\n",
    "                break\n",
    "            if user_place_id[place_idx] == tweet[\"user\"][\"id\"]:\n",
    "                if place_idx < 29218:\n",
    "                    place_idx += 1\n",
    "                break\n",
    "            if tweet[\"geo\"] is not None:\n",
    "                new_dict = {}\n",
    "                new_dict[\"type\"] = \"Point\"\n",
    "                new_dict[\"coordinates\"] = []\n",
    "                new_dict[\"coordinates\"].append(tweet[\"geo\"][\"coordinates\"][1])\n",
    "                new_dict[\"coordinates\"].append(tweet[\"geo\"][\"coordinates\"][0])\n",
    "                \n",
    "                geometry = Point(new_dict['coordinates'])\n",
    "\n",
    "                pt = gpd.GeoDataFrame({'geometry': [geometry]})\n",
    "                pt = pt.set_crs('epsg:4326')\n",
    "\n",
    "                intersections = gpd.overlay(pt, df, how='intersection', keep_geom_type=False)\n",
    "                name = intersections[\"name\"]\n",
    "                if name.empty is False:\n",
    "                    city = name.iloc[0]\n",
    "                    city = unidecode(city)\n",
    "                    city = city.lower()\n",
    "                    user_dict[city] += 1\n",
    "                    to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                    went_in = True\n",
    "                    \n",
    "\n",
    "        if went_in:           \n",
    "            city = max(user_dict, key = user_dict.get)\n",
    "            city_data[city] += 1\n",
    "            geoCnt += 1\n",
    "            user_geo_id.append(to_be_appended)\n",
    "            went_in = False\n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"Successful Count\": geoCnt, \"UserBioLoc idx\": userloc_idx, \"TweetPlace idx\": place_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Runtime: 37:02 (script)\n",
    "Users that had a [\"geo\"] but no user geo info nor tweet place info: 3904\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_geo_WO_guess.txt', 'w') as file:\n",
    "    for item in user_geo_id:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_geo_WO_guess.txt', 'r') as file:\n",
    "    user_geo_id = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/main_cities_finished_3_WO_guess.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(city_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/main_cities_finished_3_WO_guess.json\", \"r\") as file:\n",
    "    city_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Total number of users: 515 098\n",
    "Total number of users with the location info: 150 801\n",
    "29.27%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
