{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip \n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "PATH = \"C:/Users/alpye/OneDrive/Desktop/DATA/coalition_3.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityList = []\n",
    "\n",
    "with open(\"data/cities.txt\", \"r\", encoding = \"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = unidecode(line)\n",
    "        line = line.strip().lower()\n",
    "        cityList.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get them in a dictionary format, set all their values to 0 and save them as a JSON file\n",
    "\n",
    "data_dict = {key: 0 for key in cityList}\n",
    "\n",
    "file_path = 'data/main_cities.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(data_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This JSON file has populations of the cities in Turkey\n",
    "\n",
    "with open(\"data/populations.json\", \"r\") as file:\n",
    "    populations = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/city_street.xlsx')\n",
    "\n",
    "ilce_dict = {}\n",
    "semt_dict = {}\n",
    "mah_dict = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    main_key = unidecode(row['il'].strip().lower())\n",
    "    sub_key = unidecode(row['ilçe'].strip().lower())\n",
    "    sub_sub_key = unidecode(row['semt_bucak_belde'].strip().lower())\n",
    "    value = (unidecode(row[\"Mahalle\"].strip().lower()))[:-4] # Exlude MAH\n",
    "\n",
    "    ilce_dict.setdefault(main_key, {}).setdefault(sub_key, 0)\n",
    "    semt_dict.setdefault(main_key, {}).setdefault(sub_sub_key, 0)\n",
    "    mah_dict.setdefault(main_key, {}).setdefault(value, 0)\n",
    "\n",
    "# DISCLAIMER: The values of these dictionaries were useless.\n",
    "# I realized that while I was making progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 3 seperate lists to check in the future\n",
    "\n",
    "ilce_list = []\n",
    "semt_list = []\n",
    "mah_list = []\n",
    "\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ilce = unidecode(row['ilçe'].strip().lower())\n",
    "    semt = unidecode(row['semt_bucak_belde'].strip().lower())\n",
    "    mah = (unidecode(row[\"Mahalle\"].strip().lower()))[:-4] # Exlude the MAH\n",
    "\n",
    "    if ilce not in ilce_list:\n",
    "        ilce_list.append(ilce)\n",
    "    if semt not in semt_list:\n",
    "        semt_list.append(semt)\n",
    "    if mah not in mah_list:\n",
    "        mah_list.append(mah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_main_key(nested_dict, middle_key):\n",
    "    for main_key, inner_dict in nested_dict.items():\n",
    "        if middle_key in inner_dict:\n",
    "            return main_key\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the JSON file as variable \"data\"\n",
    "\n",
    "with open(\"data/main_cities.json\", \"r\") as file:\n",
    "    city_data = json.load(file)\n",
    "\n",
    "# checks for [\"user\"][\"location\"], appends the user's id's in a list. Also adds to the city_data dictionary\n",
    "\n",
    "user_list = []\n",
    "\n",
    "memberCNT = 0\n",
    "cnt = 0\n",
    "with gzip.open(PATH, \"rt\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        for tweet in data:\n",
    "            if tweet[\"user\"][\"location\"] != '':\n",
    "                loc = unidecode(tweet[\"user\"][\"location\"].strip())\n",
    "                loc = loc.lower()\n",
    "                if \"/\" in loc:\n",
    "                    loc = loc.split(\"/\")\n",
    "                elif \",\" in loc:\n",
    "                    loc = loc.split(\",\")\n",
    "                else:\n",
    "                    loc = loc.split(\" \")\n",
    "                loc = [element.replace(\" \", \"\") for element in loc]\n",
    "\n",
    "                common_elements = set(loc).intersection(cityList)\n",
    "                if common_elements:\n",
    "                    city = list(common_elements)[0]\n",
    "                    city_data[city] += 1\n",
    "                    memberCNT += 1\n",
    "                    user_list.append(tweet[\"user\"][\"id\"])\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    common_elements = set(loc).intersection(ilce_list)\n",
    "                    if common_elements:\n",
    "                        if len(list(common_elements)) > 1:\n",
    "                            final = 0\n",
    "                            final_idx = -1\n",
    "                            for i in list(common_elements):\n",
    "                                search = find_main_key(ilce_dict, i)\n",
    "                                idx = cityList.index(search)\n",
    "                                pop = populations[idx][\"population\"]\n",
    "                                if final < pop:\n",
    "                                    final = pop\n",
    "                                    final_idx = idx\n",
    "                            \n",
    "                            city = cityList[final_idx]\n",
    "                        else:\n",
    "                            ilce = list(common_elements)[0]\n",
    "                            city = find_main_key(ilce_dict, ilce)\n",
    "                        \n",
    "                        city_data[city] += 1\n",
    "                        memberCNT += 1\n",
    "                        user_list.append(tweet[\"user\"][\"id\"])\n",
    "                        break\n",
    "                    \n",
    "                    else:\n",
    "                        common_elements = set(loc).intersection(semt_list)\n",
    "                        if common_elements:\n",
    "                            if len(list(common_elements)) > 1:\n",
    "                                final = 0\n",
    "                                final_idx = -1\n",
    "                                for i in list(common_elements):\n",
    "                                    search = find_main_key(semt_dict, i)\n",
    "                                    idx = cityList.index(search)\n",
    "                                    pop = populations[idx][\"population\"]\n",
    "                                    if final < pop:\n",
    "                                        final = pop\n",
    "                                        final_idx = idx\n",
    "                            \n",
    "                                city = cityList[final_idx]\n",
    "                            else:\n",
    "                                semt = list(common_elements)[0]\n",
    "                                city = find_main_key(semt_dict, semt)\n",
    "                            \n",
    "                            city_data[city] += 1\n",
    "                            memberCNT += 1\n",
    "                            user_list.append(tweet[\"user\"][\"id\"])\n",
    "                            break\n",
    "\n",
    "                        else:\n",
    "                            common_elements = set(loc).intersection(mah_list)\n",
    "                            if common_elements:\n",
    "                                if len(list(common_elements)) > 1:\n",
    "                                    final = 0\n",
    "                                    final_idx = -1\n",
    "                                    for i in list(common_elements):\n",
    "                                        search = find_main_key(mah_dict, i)\n",
    "                                        idx = cityList.index(search)\n",
    "                                        pop = populations[idx][\"population\"]\n",
    "                                        if final < pop:\n",
    "                                            final = pop\n",
    "                                            final_idx = idx\n",
    "                                \n",
    "                                    city = cityList[final_idx]\n",
    "                                else:\n",
    "                                    mah = list(common_elements)[0]\n",
    "                                    city = find_main_key(mah_dict, mah)\n",
    "                                \n",
    "                                city_data[city] += 1\n",
    "                                memberCNT += 1\n",
    "                                user_list.append(tweet[\"user\"][\"id\"])\n",
    "                                break\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"Successful Count\": memberCNT})         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime: 1 hour 21 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Total users: 515 098\n",
    "Users with legit location in their bio: 117 866\n",
    "22.9%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/main_cities_finished.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(city_data, file, indent=4)\n",
    "\n",
    "with open('data/user_list.txt', 'w') as file:\n",
    "    for item in user_list:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list.txt', 'r') as file:\n",
    "    user_list = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/main_cities_finished.json\", \"r\") as file:\n",
    "    city_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks for [\"place\"][\"full_name\"], appends the user's id's in a list. Also adds to the city_data dictionary\n",
    "\n",
    "user_place_id = []\n",
    "\n",
    "user_avoid = 0\n",
    "memberCNT = 0\n",
    "cnt = 0\n",
    "with gzip.open(PATH, \"rt\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        user_dict = {key: 0 for key in cityList}\n",
    "        went_in = False\n",
    "        for tweet in data:\n",
    "            if tweet[\"user\"][\"id\"] == user_list[user_avoid]:\n",
    "                if user_avoid < 117865:\n",
    "                    user_avoid += 1\n",
    "                break\n",
    "            else:\n",
    "                if tweet[\"place\"] is not None:\n",
    "                    loc = unidecode(tweet[\"place\"][\"full_name\"].strip())\n",
    "                    loc = loc.lower()\n",
    "                    if \"/\" in loc:\n",
    "                        loc = loc.split(\"/\")\n",
    "                    elif \",\" in loc:\n",
    "                        loc = loc.split(\",\")\n",
    "                    else:\n",
    "                        loc = loc.split(\" \")\n",
    "                    loc = [element.replace(\" \", \"\") for element in loc]\n",
    "\n",
    "                    common_elements = set(loc).intersection(cityList)\n",
    "                    if common_elements:\n",
    "                        city = list(common_elements)[0]\n",
    "                        user_dict[city] += 1\n",
    "                        went_in = True\n",
    "                        to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                        \n",
    "                    else:\n",
    "                        common_elements = set(loc).intersection(ilce_list)\n",
    "                        if common_elements:\n",
    "                            if len(list(common_elements)) > 1:\n",
    "                                final = 0\n",
    "                                final_idx = -1\n",
    "                                for i in list(common_elements):\n",
    "                                    search = find_main_key(ilce_dict, i)\n",
    "                                    idx = cityList.index(search)\n",
    "                                    pop = populations[idx][\"population\"]\n",
    "                                    if final < pop:\n",
    "                                        final = pop\n",
    "                                        final_idx = idx\n",
    "                                \n",
    "                                city = cityList[final_idx]\n",
    "                            else:\n",
    "                                ilce = list(common_elements)[0]\n",
    "                                city = find_main_key(ilce_dict, ilce)\n",
    "                            \n",
    "                            user_dict[city] += 1\n",
    "                            went_in = True\n",
    "                            to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                        \n",
    "                        else:\n",
    "                            common_elements = set(loc).intersection(semt_list)\n",
    "                            if common_elements:\n",
    "                                if len(list(common_elements)) > 1:\n",
    "                                    final = 0\n",
    "                                    final_idx = -1\n",
    "                                    for i in list(common_elements):\n",
    "                                        search = find_main_key(semt_dict, i)\n",
    "                                        idx = cityList.index(search)\n",
    "                                        pop = populations[idx][\"population\"]\n",
    "                                        if final < pop:\n",
    "                                            final = pop\n",
    "                                            final_idx = idx\n",
    "                                \n",
    "                                    city = cityList[final_idx]\n",
    "                                else:\n",
    "                                    semt = list(common_elements)[0]\n",
    "                                    city = find_main_key(semt_dict, semt)\n",
    "                                \n",
    "                                user_dict[city] += 1\n",
    "                                went_in = True\n",
    "                                to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                                \n",
    "\n",
    "                            else:\n",
    "                                common_elements = set(loc).intersection(mah_list)\n",
    "                                if common_elements:\n",
    "                                    if len(list(common_elements)) > 1:\n",
    "                                        final = 0\n",
    "                                        final_idx = -1\n",
    "                                        for i in list(common_elements):\n",
    "                                            search = find_main_key(mah_dict, i)\n",
    "                                            idx = cityList.index(search)\n",
    "                                            pop = populations[idx][\"population\"]\n",
    "                                            if final < pop:\n",
    "                                                final = pop\n",
    "                                                final_idx = idx\n",
    "                                    \n",
    "                                        city = cityList[final_idx]\n",
    "                                    else:\n",
    "                                        mah = list(common_elements)[0]\n",
    "                                        city = find_main_key(mah_dict, mah)\n",
    "                                    \n",
    "                                    user_dict[city] += 1\n",
    "                                    went_in = True\n",
    "                                    to_be_appended = tweet[\"user\"][\"id\"]\n",
    "\n",
    "\n",
    "        if went_in:           \n",
    "            city = max(user_dict, key = user_dict.get)\n",
    "            city_data[city] += 1\n",
    "            memberCNT += 1\n",
    "            user_place_id.append(to_be_appended)\n",
    "            went_in = False                            \n",
    "                                \n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"Successful Count\": memberCNT, \"User List idx\": user_avoid})         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Runtime: 33:30\n",
    "Users with legit geo info in their tweets (excluding the ones with geo info in their bio): 29 194\n",
    "5.67%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/main_cities_finished_2.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(city_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/main_cities_finished_2.json\", \"r\") as file:\n",
    "    city_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_place.txt', 'w') as file:\n",
    "    for item in user_place_id:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_place.txt', 'r') as file:\n",
    "    user_place_id = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ran on a script since it takes a long time, checked for [\"geo\"]\n",
    "\n",
    "user_geo_id = []\n",
    "\n",
    "geoCnt = 0\n",
    "place_idx = 0\n",
    "userloc_idx = 0\n",
    "cnt = 0\n",
    "with gzip.open(PATH, \"rt\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        user_dict = {key: 0 for key in cityList}\n",
    "        went_in = False\n",
    "        for tweet in data:\n",
    "            if user_list[userloc_idx] == tweet[\"user\"][\"id\"]:\n",
    "                if userloc_idx < 117865:\n",
    "                    userloc_idx += 1\n",
    "                break\n",
    "            if user_place_id[place_idx] == tweet[\"user\"][\"id\"]:\n",
    "                if place_idx < 29193:\n",
    "                    place_idx += 1\n",
    "                break\n",
    "            if tweet[\"geo\"] is not None:\n",
    "                new_dict = {}\n",
    "                new_dict[\"type\"] = \"Point\"\n",
    "                new_dict[\"coordinates\"] = []\n",
    "                new_dict[\"coordinates\"].append(tweet[\"geo\"][\"coordinates\"][1])\n",
    "                new_dict[\"coordinates\"].append(tweet[\"geo\"][\"coordinates\"][0])\n",
    "                with open(\"data/temp.geojson\", \"w\") as f:\n",
    "                    json.dump(new_dict, f)\n",
    "\n",
    "                pt = gpd.read_file(\"data/temp.geojson\")\n",
    "                df = gpd.read_file(\"data/turkey.geojson\")\n",
    "                intersections = gpd.overlay(pt, df, how='intersection')\n",
    "                name = intersections[\"name\"]\n",
    "                if name.empty is False:\n",
    "                    city = name.iloc[0]\n",
    "                    city = unidecode(city)\n",
    "                    city = city.lower()\n",
    "                    user_dict[city] += 1\n",
    "                    to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                    went_in = True\n",
    "\n",
    "        if went_in:           \n",
    "            city = max(user_dict, key = user_dict.get)\n",
    "            city_data[city] += 1\n",
    "            geoCnt += 1\n",
    "            user_geo_id.append(to_be_appended)\n",
    "            went_in = False\n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"Successful Count\": geoCnt, \"UserBioLoc idx\": userloc_idx, \"TweetPlace idx\": place_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Runtime: 1 hour 45 minutes (on a script)\n",
    "Users that had a [\"geo\"] but no user geo info nor tweet place info: 3893\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_geo.txt', 'w') as file:\n",
    "    for item in user_geo_id:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_geo.txt', 'r') as file:\n",
    "    user_geo_id = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/main_cities_finished_3.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(city_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/main_cities_finished_3.json\", \"r\") as file:\n",
    "    city_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Total number of users: 515 098\n",
    "Total number of users with the location info: 150 953\n",
    "29.3%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got a dictionary to test\n",
    "# Format: {user id: [tweet content]}\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "geo_idx = 0\n",
    "place_idx = 0\n",
    "userloc_idx = 0\n",
    "cnt = 0\n",
    "up = 0\n",
    "with gzip.open(PATH, \"rt\", encoding=\"utf-8\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        temp_list = []\n",
    "        went_in_loc = False\n",
    "        went_in_place = False\n",
    "        went_in_geo = False\n",
    "        for tweet in data:\n",
    "            if user_list[userloc_idx] == tweet[\"user\"][\"id\"]:\n",
    "                temp_list.append(tweet[\"full_text\"])\n",
    "                went_in_loc = True\n",
    "                key = user_list[userloc_idx] \n",
    "\n",
    "            elif user_place_id[place_idx] == tweet[\"user\"][\"id\"]:\n",
    "                temp_list.append(tweet[\"full_text\"])\n",
    "                went_in_place = True\n",
    "                key = user_place_id[place_idx]\n",
    "\n",
    "            elif tweet[\"user\"][\"id\"] == user_geo_id[geo_idx]:\n",
    "                temp_list.append(tweet[\"full_text\"])\n",
    "                went_in_geo = True\n",
    "                key = user_geo_id[geo_idx]\n",
    "\n",
    "        if went_in_loc:\n",
    "            if userloc_idx < 117865:\n",
    "                userloc_idx += 1\n",
    "                test_dict[str(key)] = temp_list\n",
    "                up += 1\n",
    "                went_in_loc = False\n",
    "        \n",
    "        elif went_in_place:\n",
    "            if place_idx < 29193:\n",
    "                place_idx += 1\n",
    "                test_dict[str(key)] = temp_list\n",
    "                up += 1\n",
    "                went_in_place = False\n",
    "\n",
    "        elif went_in_geo:\n",
    "            if geo_idx < 3892:\n",
    "                geo_idx += 1\n",
    "                test_dict[str(key)] = temp_list\n",
    "                up += 1\n",
    "                went_in_geo = False\n",
    "\n",
    "        if up == 2:\n",
    "            break\n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"GeoIdx\": geo_idx, \"UserBioLoc idx\": userloc_idx, \"TweetPlace idx\": place_idx, \"DictElement Count\": up})\n",
    "\n",
    "# Runtime: 35 minutes\n",
    "# 150950 keys (users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/test_dict.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(test_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/test_dict.json\", \"r\") as file:\n",
    "    test_dict = json.load(file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
