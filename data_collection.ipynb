{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip \n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "PATH = \"C:/Users/alpye/OneDrive/Desktop/DATA/coalition_3.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityList = []\n",
    "\n",
    "with open(\"data/cities.txt\", \"r\", encoding = \"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = unidecode(line)\n",
    "        line = line.strip().lower()\n",
    "        cityList.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get them in a dictionary format, set all their values to 0 and save them as a JSON file\n",
    "\n",
    "data_dict = {key: 0 for key in cityList}\n",
    "\n",
    "file_path = 'data/main_cities.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(data_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This JSON file has populations of the cities in Turkey\n",
    "\n",
    "with open(\"data/populations.json\", \"r\") as file:\n",
    "    populations = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/city_street.xlsx')\n",
    "\n",
    "ilce_dict = {}\n",
    "semt_dict = {}\n",
    "mah_dict = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    main_key = unidecode(row['il'].strip().lower())\n",
    "    sub_key = unidecode(row['ilÃ§e'].strip().lower())\n",
    "    sub_sub_key = unidecode(row['semt_bucak_belde'].strip().lower())\n",
    "    value = (unidecode(row[\"Mahalle\"].strip().lower()))[:-4] # Exlude MAH\n",
    "\n",
    "    ilce_dict.setdefault(main_key, {}).setdefault(sub_key, 0)\n",
    "    semt_dict.setdefault(main_key, {}).setdefault(sub_sub_key, 0)\n",
    "    mah_dict.setdefault(main_key, {}).setdefault(value, 0)\n",
    "\n",
    "# DISCLAIMER: The values of these dictionaries were useless.\n",
    "# I realized that while I was making progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 3 seperate lists to check in the future\n",
    "\n",
    "ilce_list = []\n",
    "semt_list = []\n",
    "mah_list = []\n",
    "\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ilce = unidecode(row['ilÃ§e'].strip().lower())\n",
    "    semt = unidecode(row['semt_bucak_belde'].strip().lower())\n",
    "    mah = (unidecode(row[\"Mahalle\"].strip().lower()))[:-4] # Exlude the MAH\n",
    "\n",
    "    if ilce not in ilce_list:\n",
    "        ilce_list.append(ilce)\n",
    "    if semt not in semt_list:\n",
    "        semt_list.append(semt)\n",
    "    if mah not in mah_list:\n",
    "        mah_list.append(mah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_main_key(nested_dict, middle_key):\n",
    "    for main_key, inner_dict in nested_dict.items():\n",
    "        if middle_key in inner_dict:\n",
    "            return main_key\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the JSON file as variable \"data\"\n",
    "\n",
    "with open(\"data/main_cities.json\", \"r\") as file:\n",
    "    city_data = json.load(file)\n",
    "\n",
    "# checks for [\"user\"][\"location\"], appends the user's id's in a list. Also adds to the city_data dictionary\n",
    "\n",
    "user_list = []\n",
    "\n",
    "memberCNT = 0\n",
    "cnt = 0\n",
    "with gzip.open(PATH, \"rt\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        for tweet in data:\n",
    "            if tweet[\"user\"][\"location\"] != '':\n",
    "                loc = unidecode(tweet[\"user\"][\"location\"].strip())\n",
    "                loc = loc.lower()\n",
    "                if \"/\" in loc:\n",
    "                    loc = loc.split(\"/\")\n",
    "                elif \",\" in loc:\n",
    "                    loc = loc.split(\",\")\n",
    "                else:\n",
    "                    loc = loc.split(\" \")\n",
    "                loc = [element.replace(\" \", \"\") for element in loc]\n",
    "\n",
    "                common_elements = set(loc).intersection(cityList)\n",
    "                if common_elements:\n",
    "                    city = list(common_elements)[0]\n",
    "                    city_data[city] += 1\n",
    "                    memberCNT += 1\n",
    "                    user_list.append(tweet[\"user\"][\"id\"])\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    common_elements = set(loc).intersection(ilce_list)\n",
    "                    if common_elements:\n",
    "                        if len(list(common_elements)) > 1:\n",
    "                            final = 0\n",
    "                            final_idx = -1\n",
    "                            for i in list(common_elements):\n",
    "                                search = find_main_key(ilce_dict, i)\n",
    "                                idx = cityList.index(search)\n",
    "                                pop = populations[idx][\"population\"]\n",
    "                                if final < pop:\n",
    "                                    final = pop\n",
    "                                    final_idx = idx\n",
    "                            \n",
    "                            city = cityList[final_idx]\n",
    "                        else:\n",
    "                            ilce = list(common_elements)[0]\n",
    "                            city = find_main_key(ilce_dict, ilce)\n",
    "                        \n",
    "                        city_data[city] += 1\n",
    "                        memberCNT += 1\n",
    "                        user_list.append(tweet[\"user\"][\"id\"])\n",
    "                        break\n",
    "                    \n",
    "                    else:\n",
    "                        common_elements = set(loc).intersection(semt_list)\n",
    "                        if common_elements:\n",
    "                            if len(list(common_elements)) > 1:\n",
    "                                final = 0\n",
    "                                final_idx = -1\n",
    "                                for i in list(common_elements):\n",
    "                                    search = find_main_key(semt_dict, i)\n",
    "                                    idx = cityList.index(search)\n",
    "                                    pop = populations[idx][\"population\"]\n",
    "                                    if final < pop:\n",
    "                                        final = pop\n",
    "                                        final_idx = idx\n",
    "                            \n",
    "                                city = cityList[final_idx]\n",
    "                            else:\n",
    "                                semt = list(common_elements)[0]\n",
    "                                city = find_main_key(semt_dict, semt)\n",
    "                            \n",
    "                            city_data[city] += 1\n",
    "                            memberCNT += 1\n",
    "                            user_list.append(tweet[\"user\"][\"id\"])\n",
    "                            break\n",
    "\n",
    "                        else:\n",
    "                            common_elements = set(loc).intersection(mah_list)\n",
    "                            if common_elements:\n",
    "                                if len(list(common_elements)) > 1:\n",
    "                                    final = 0\n",
    "                                    final_idx = -1\n",
    "                                    for i in list(common_elements):\n",
    "                                        search = find_main_key(mah_dict, i)\n",
    "                                        idx = cityList.index(search)\n",
    "                                        pop = populations[idx][\"population\"]\n",
    "                                        if final < pop:\n",
    "                                            final = pop\n",
    "                                            final_idx = idx\n",
    "                                \n",
    "                                    city = cityList[final_idx]\n",
    "                                else:\n",
    "                                    mah = list(common_elements)[0]\n",
    "                                    city = find_main_key(mah_dict, mah)\n",
    "                                \n",
    "                                city_data[city] += 1\n",
    "                                memberCNT += 1\n",
    "                                user_list.append(tweet[\"user\"][\"id\"])\n",
    "                                break\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"Successful Count\": memberCNT})         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime: 1 hour 21 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Total users: 515 098\n",
    "Users with legit location in their bio: 117 866\n",
    "22.9%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/main_cities_finished.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(city_data, file, indent=4)\n",
    "\n",
    "with open('data/user_list.txt', 'w') as file:\n",
    "    for item in user_list:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list.txt', 'r') as file:\n",
    "    user_list = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/main_cities_finished.json\", \"r\") as file:\n",
    "    city_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks for [\"place\"][\"full_name\"], appends the user's id's in a list. Also adds to the city_data dictionary\n",
    "\n",
    "user_place_id = []\n",
    "\n",
    "user_avoid = 0\n",
    "memberCNT = 0\n",
    "cnt = 0\n",
    "with gzip.open(PATH, \"rt\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        user_dict = {key: 0 for key in cityList}\n",
    "        went_in = False\n",
    "        for tweet in data:\n",
    "            if tweet[\"user\"][\"id\"] == user_list[user_avoid]:\n",
    "                if user_avoid < 117865:\n",
    "                    user_avoid += 1\n",
    "                break\n",
    "            else:\n",
    "                if tweet[\"place\"] is not None:\n",
    "                    loc = unidecode(tweet[\"place\"][\"full_name\"].strip())\n",
    "                    loc = loc.lower()\n",
    "                    if \"/\" in loc:\n",
    "                        loc = loc.split(\"/\")\n",
    "                    elif \",\" in loc:\n",
    "                        loc = loc.split(\",\")\n",
    "                    else:\n",
    "                        loc = loc.split(\" \")\n",
    "                    loc = [element.replace(\" \", \"\") for element in loc]\n",
    "\n",
    "                    common_elements = set(loc).intersection(cityList)\n",
    "                    if common_elements:\n",
    "                        city = list(common_elements)[0]\n",
    "                        user_dict[city] += 1\n",
    "                        went_in = True\n",
    "                        to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                        \n",
    "                    else:\n",
    "                        common_elements = set(loc).intersection(ilce_list)\n",
    "                        if common_elements:\n",
    "                            if len(list(common_elements)) > 1:\n",
    "                                final = 0\n",
    "                                final_idx = -1\n",
    "                                for i in list(common_elements):\n",
    "                                    search = find_main_key(ilce_dict, i)\n",
    "                                    idx = cityList.index(search)\n",
    "                                    pop = populations[idx][\"population\"]\n",
    "                                    if final < pop:\n",
    "                                        final = pop\n",
    "                                        final_idx = idx\n",
    "                                \n",
    "                                city = cityList[final_idx]\n",
    "                            else:\n",
    "                                ilce = list(common_elements)[0]\n",
    "                                city = find_main_key(ilce_dict, ilce)\n",
    "                            \n",
    "                            user_dict[city] += 1\n",
    "                            went_in = True\n",
    "                            to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                        \n",
    "                        else:\n",
    "                            common_elements = set(loc).intersection(semt_list)\n",
    "                            if common_elements:\n",
    "                                if len(list(common_elements)) > 1:\n",
    "                                    final = 0\n",
    "                                    final_idx = -1\n",
    "                                    for i in list(common_elements):\n",
    "                                        search = find_main_key(semt_dict, i)\n",
    "                                        idx = cityList.index(search)\n",
    "                                        pop = populations[idx][\"population\"]\n",
    "                                        if final < pop:\n",
    "                                            final = pop\n",
    "                                            final_idx = idx\n",
    "                                \n",
    "                                    city = cityList[final_idx]\n",
    "                                else:\n",
    "                                    semt = list(common_elements)[0]\n",
    "                                    city = find_main_key(semt_dict, semt)\n",
    "                                \n",
    "                                user_dict[city] += 1\n",
    "                                went_in = True\n",
    "                                to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                                \n",
    "\n",
    "                            else:\n",
    "                                common_elements = set(loc).intersection(mah_list)\n",
    "                                if common_elements:\n",
    "                                    if len(list(common_elements)) > 1:\n",
    "                                        final = 0\n",
    "                                        final_idx = -1\n",
    "                                        for i in list(common_elements):\n",
    "                                            search = find_main_key(mah_dict, i)\n",
    "                                            idx = cityList.index(search)\n",
    "                                            pop = populations[idx][\"population\"]\n",
    "                                            if final < pop:\n",
    "                                                final = pop\n",
    "                                                final_idx = idx\n",
    "                                    \n",
    "                                        city = cityList[final_idx]\n",
    "                                    else:\n",
    "                                        mah = list(common_elements)[0]\n",
    "                                        city = find_main_key(mah_dict, mah)\n",
    "                                    \n",
    "                                    user_dict[city] += 1\n",
    "                                    went_in = True\n",
    "                                    to_be_appended = tweet[\"user\"][\"id\"]\n",
    "\n",
    "\n",
    "        if went_in:           \n",
    "            city = max(user_dict, key = user_dict.get)\n",
    "            city_data[city] += 1\n",
    "            memberCNT += 1\n",
    "            user_place_id.append(to_be_appended)\n",
    "            went_in = False                            \n",
    "                                \n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"Successful Count\": memberCNT, \"User List idx\": user_avoid})         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Runtime: 33:30\n",
    "Users with legit geo info in their tweets (excluding the ones with geo info in their bio): 29 194\n",
    "5.67%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/main_cities_finished_2.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(city_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/main_cities_finished_2.json\", \"r\") as file:\n",
    "    city_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_place.txt', 'w') as file:\n",
    "    for item in user_place_id:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_place.txt', 'r') as file:\n",
    "    user_place_id = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ran on a script since it takes a long time, checked for [\"geo\"]\n",
    "\n",
    "user_geo_id = []\n",
    "\n",
    "geoCnt = 0\n",
    "place_idx = 0\n",
    "userloc_idx = 0\n",
    "cnt = 0\n",
    "with gzip.open(PATH, \"rt\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        user_dict = {key: 0 for key in cityList}\n",
    "        went_in = False\n",
    "        for tweet in data:\n",
    "            if user_list[userloc_idx] == tweet[\"user\"][\"id\"]:\n",
    "                if userloc_idx < 117865:\n",
    "                    userloc_idx += 1\n",
    "                break\n",
    "            if user_place_id[place_idx] == tweet[\"user\"][\"id\"]:\n",
    "                if place_idx < 29193:\n",
    "                    place_idx += 1\n",
    "                break\n",
    "            if tweet[\"geo\"] is not None:\n",
    "                new_dict = {}\n",
    "                new_dict[\"type\"] = \"Point\"\n",
    "                new_dict[\"coordinates\"] = []\n",
    "                new_dict[\"coordinates\"].append(tweet[\"geo\"][\"coordinates\"][1])\n",
    "                new_dict[\"coordinates\"].append(tweet[\"geo\"][\"coordinates\"][0])\n",
    "                with open(\"data/temp.geojson\", \"w\") as f:\n",
    "                    json.dump(new_dict, f)\n",
    "\n",
    "                pt = gpd.read_file(\"data/temp.geojson\")\n",
    "                df = gpd.read_file(\"data/turkey.geojson\")\n",
    "                intersections = gpd.overlay(pt, df, how='intersection')\n",
    "                name = intersections[\"name\"]\n",
    "                if name.empty is False:\n",
    "                    city = name.iloc[0]\n",
    "                    city = unidecode(city)\n",
    "                    city = city.lower()\n",
    "                    user_dict[city] += 1\n",
    "                    to_be_appended = tweet[\"user\"][\"id\"]\n",
    "                    went_in = True\n",
    "\n",
    "        if went_in:           \n",
    "            city = max(user_dict, key = user_dict.get)\n",
    "            city_data[city] += 1\n",
    "            geoCnt += 1\n",
    "            user_geo_id.append(to_be_appended)\n",
    "            went_in = False\n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"Successful Count\": geoCnt, \"UserBioLoc idx\": userloc_idx, \"TweetPlace idx\": place_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Runtime: 1 hour 45 minutes (on a script)\n",
    "Users that had a [\"geo\"] but no user geo info nor tweet place info: 3893\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_geo.txt', 'w') as file:\n",
    "    for item in user_geo_id:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/user_list_geo.txt', 'r') as file:\n",
    "    user_geo_id = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/main_cities_finished_3.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(city_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/main_cities_finished_3.json\", \"r\") as file:\n",
    "    city_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Total number of users: 515 098\n",
    "Total number of users with the location info: 150 953\n",
    "29.3%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got a dictionary to test\n",
    "# Format: {user id: [tweet content]}\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "geo_idx = 0\n",
    "place_idx = 0\n",
    "userloc_idx = 0\n",
    "cnt = 0\n",
    "up = 0\n",
    "with gzip.open(PATH, \"rt\", encoding=\"utf-8\") as fh:\n",
    "    pbar = tqdm(fh)\n",
    "    for i in pbar:\n",
    "        uid, data = i.split(\"\\t\") \n",
    "        data = json.loads(data) # Makes the json into a Python dictionary\n",
    "        temp_list = []\n",
    "        went_in_loc = False\n",
    "        went_in_place = False\n",
    "        went_in_geo = False\n",
    "        for tweet in data:\n",
    "            if user_list[userloc_idx] == tweet[\"user\"][\"id\"]:\n",
    "                temp_list.append(tweet[\"full_text\"])\n",
    "                went_in_loc = True\n",
    "                key = user_list[userloc_idx] \n",
    "\n",
    "            elif user_place_id[place_idx] == tweet[\"user\"][\"id\"]:\n",
    "                temp_list.append(tweet[\"full_text\"])\n",
    "                went_in_place = True\n",
    "                key = user_place_id[place_idx]\n",
    "\n",
    "            elif tweet[\"user\"][\"id\"] == user_geo_id[geo_idx]:\n",
    "                temp_list.append(tweet[\"full_text\"])\n",
    "                went_in_geo = True\n",
    "                key = user_geo_id[geo_idx]\n",
    "\n",
    "        if went_in_loc:\n",
    "            if userloc_idx < 117865:\n",
    "                userloc_idx += 1\n",
    "                test_dict[str(key)] = temp_list\n",
    "                up += 1\n",
    "                went_in_loc = False\n",
    "        \n",
    "        elif went_in_place:\n",
    "            if place_idx < 29193:\n",
    "                place_idx += 1\n",
    "                test_dict[str(key)] = temp_list\n",
    "                up += 1\n",
    "                went_in_place = False\n",
    "\n",
    "        elif went_in_geo:\n",
    "            if geo_idx < 3892:\n",
    "                geo_idx += 1\n",
    "                test_dict[str(key)] = temp_list\n",
    "                up += 1\n",
    "                went_in_geo = False\n",
    "\n",
    "        if up == 2:\n",
    "            break\n",
    "        cnt += 1\n",
    "        pbar.set_postfix({\"Count\": cnt, \"GeoIdx\": geo_idx, \"UserBioLoc idx\": userloc_idx, \"TweetPlace idx\": place_idx, \"DictElement Count\": up})\n",
    "\n",
    "# Runtime: 35 minutes\n",
    "# 150950 keys (users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/test_dict.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(test_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/test_dict.json\", \"r\") as file:\n",
    "    test_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@MHP_Bilgi Senin son nefesin yakÄ±ndÄ±r senin iÃ§in sorun olmayacaktÄ±r. Peki bu vatanÄ±n genÃ§liÄŸi geleceÄŸi ne olacaktÄ±r?', 'Herkes Ã¼niversite piÅŸmanlÄ±ktÄ±r, Ã¼niversite okudum ÅŸimdi kuryeyim falan diyor. Madem kurye olcam ÅŸansÄ±mÄ± yurt dÄ±ÅŸÄ±nda denerim?', '@KadirMisiroglu @SebilYayinevi @OsmanlilarVakfi LeÅŸini bu toprak kabul etcekmi sanÄ±yosunuz kanÄ± bozuk ÅŸerefsiz! Sen ileri geri konuÅŸabilesin diye bu topraklarda ÅŸehitler verilmedi arap iti', 'Memleketimin araplaÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rmektense sÄ±nÄ±r dÄ±ÅŸÄ± edilip yeni bir hayat kurmayÄ± yeÄŸlerim! Araplara karÅŸÄ± sonuna kadar IrkÃ§Ä±yÄ±m!', '@aleynakrolu1 Yak aga yak yak', '@samiltayyar27 Ãœlkeyi boka sÃ¼rÃ¼kleyen isimler arasÄ±na girdi sayÄ±n CumhurbaÅŸkanÄ± hala diyorsunuz ki reis. ÃœslÃ¼bumu mazur gÃ¶rÃ¼n fakat hakikat bu...', '@FOXhaber @fatihportakal #tavizverevere Ã¼lkenin uÃ§uruma sÃ¼rÃ¼klenmesine sebep olduk.Bir gazeteci olarak soruyorum...Åžimdi ne olucak?', '@Alex10 AnlamÄ±yoz ama seviyoz be KRAL', '@samiltayyar27 BakÄ±yo gene bugÃ¼n nasÄ±l TÃ¼rkiyeye kalp krizi geÃ§irtirim diye!', '@Burakkarakayax 4 milyon liram olucaksa 3 ÅŸÄ±kkÄ±n fÄ±rsatlarÄ± gelir ayaÄŸÄ±ma', 'Bu insanlar vatanÄ± ve vatandaÅŸlarÄ± iÃ§in canlarÄ±nÄ± ortaya koymuÅŸ insanlar. Koray GÃ¼rbÃ¼z ve tÃ¼m diÄŸer gaziler saygÄ±yÄ± sonuna kadar hak ediyor. https://t.co/D9jeHl97te']\n",
      "['Rusyaâ€™da yaÅŸanan dostum Mikhail Ã§ok teÅŸekkÃ¼r ederim yardÄ±mÄ±nÄ±n iÃ§in \\u2066\\u2066@AFADBaskanlik\\u2069 da bizim \\u2066@ahbap\\u2069 da https://t.co/4VTwNrdInl', '@GedikogluHavva @SelinOzyurts Selam tanÄ±ÅŸabiliriz', '#YeniProfilResmi https://t.co/UAeBdWj669', '@gi2emden Selam Tlf alabilir miyim', '@KucukkayaIsmail Bu defa gÃ¼neÅŸ bizim iÃ§in doÄŸacak', '@Haticehnm0 Wayyyy', 'BEDENÄ°MÄ° Ã–LDÃœREBÄ°LÄ°RSÄ°N DÃœÅžÃœNCELERÄ°M HEP YAÅžAYACAK 05.06.1972 @Tugbadusunur @akilsavas', 'DuruÅŸumuz belli ama yine de koyalÄ±m https://t.co/EXQe64QH1u', '@Besiktas YazÄ±k', 'Bence haftanÄ±n golÃ¼nÃ¼, BeÅŸiktaÅŸ formasÄ± giyen Michy Batshuayi attÄ±.', '#RosieriÃ§inHavaalanÄ±na', '@jk_bale  ÅŸampiyonluk BeÅŸiktaÅŸâ€™Ä±n hakkÄ±ðŸ†ðŸ†ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·ðŸ¦…ðŸ¦…ðŸ¦…ðŸ–¤ðŸ–¤ðŸ–¤ðŸ¤ðŸ¤ðŸ¤ https://t.co/vCN6b0RsZl', '@ersinduzen BeÅŸiktaÅŸ 15 en az', '@Besiktas_cArsi Ä°NCÄ°NMÄ°ÅžSÄ°N DÄ°YORUZ', '@picadambaattin 042', '@beINSPORTS_TR Bjk https://t.co/EFuuBbFHP5', '#YeniProfilResmi https://t.co/1FaordNGVr', '@slowturk_radyo @fatihuslu_ @AVCIKORAY #gitmekistiyorum eÅŸim hamile onun iÃ§in ##', '@YuruGunese', 'Ä°cinde raki geciyor diye tÃ¼rkÃ¼ dinlemek haram ama ayni rakinin sisesinden %65 vergi alip imam maasi odemek helal bu ulkede', '\"@orcunizmm: kÄ±zlarÄ±n \"sen benim 2. sevgilimsin\" yalanÄ±yla, erkeklerin \"Ã§ok sevgilim oldu ama ilk seni sevdim\" yalanÄ± Ã¶lÃ¼mÃ¼ne kapÄ±ÅŸÄ±r...\"', 'direnhamile', '@asranan supersiniz', 'baTUÄžBArÄ±ÅŸ asklarim iÃ§iÃ§e', 'hanimi kuaforde beklemek :(((', 'havuz keyfi missss', 'oley tatil zamani yarin sadece oglum ve karim ile vakit gecirecegim', 'pazartesi kendi adin bile yok pazarin golgesinde kalmissin  sali gibi carsamba gibi  kendin ol bizi bunaltma', 'ewet az kaldii gulsen dinleyin siz yatcaz kalcacaz yatcazkalcaz ortdayim', 'istanbuldan kuzular gelsin artik', 'nisan ayi seni cok seviyorum', 'BESâ€™de BEST Ã¶neriler http://t.co/tMndOLhyy3 @SigortaGundem aracÄ±lÄ±ÄŸÄ±yla', 'beyaz show candÄ±r izlenÄ±r', 'atam tarih bile sÄ±raya girdi senin iÃ§in rahat uyu 10.11.12', 'BaTuÄŸBarÄ±ÅŸ ikinizi de bugÃ¼n Ã§ok Ã¶zledim bir an Ã¶nce gidelim mutluluk ve huzur evine', '@akilsavas', '@tugcerkan1 @akilsavas o zaman oÄŸlum karÄ±m baldÄ±zÄ±m bacanaÄŸÄ±m ve ben', 'oglum karÄ±m ve ben', '@tugcerkan1 haftasonunu bekleyin yeni sÃ¼prizler olabilir', '@tugcerkan1 Ã¶zlediklerine kavusmak Ã§ok gÃ¼zel', 'iÅŸler gÃ¼Ã§ler izlemek paha biÃ§ilmez', 'karÄ±m oglum gelin artÄ±k Ã§ok Ã¶zledim', 'Ã¶zledim', 'gÃ¼naydÄ±n herkese iyi haftalar', 'maÃ§ daha yeni baslÄ±yor', 'beÅŸiktaÅŸ', 'savaÅŸ alanya yollarÄ±na dÃ¼ÅŸer', 'gelÄ±yorum onu yemeye', 'EÅž DURUMUNDAN BEN VE OÄžLUÅžUM BUGÃœN FENERBAHÃ‡ELÄ°YÄ°Z.', 'haydi beÅŸiktaÅŸÄ±m avrupa seni bekliyorrr', 'hayÄ±rlÄ± cumalar', 'oÄŸlumuz BatuÄŸ BarÄ±ÅŸ Ä±n gÃ¶beÄŸi dÃ¼ÅŸtÃ¼ oleyyyy....', 'ne sÄ±kÄ±cÄ± bir gÃ¼n bir an Ã¶nce akÅŸam olsun', 'AÅŸkÄ±mla balkon keyfi']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    first_key = list(test_dict.keys())[i]\n",
    "    first_value = test_dict[first_key]\n",
    "    print(first_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
